{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "dataset_path = \"chinese_mnist.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IuUMZvAxmWup",
        "outputId": "c3c82701-5084-4e16-aac1-4711ce2190aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   suite_id  sample_id  code  value character\n",
              "0         1          1    10      9         九\n",
              "1         1         10    10      9         九\n",
              "2         1          2    10      9         九"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7545f006-2064-4b65-8788-f733685e2962\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>suite_id</th>\n",
              "      <th>sample_id</th>\n",
              "      <th>code</th>\n",
              "      <th>value</th>\n",
              "      <th>character</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>九</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>九</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>九</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7545f006-2064-4b65-8788-f733685e2962')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7545f006-2064-4b65-8788-f733685e2962 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7545f006-2064-4b65-8788-f733685e2962');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-77477c02-8eff-43d7-b3c7-ffc912a03036\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77477c02-8eff-43d7-b3c7-ffc912a03036')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-77477c02-8eff-43d7-b3c7-ffc912a03036 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15000,\n  \"fields\": [\n    {\n      \"column\": \"suite_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 1,\n        \"max\": 100,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          84,\n          57,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          10,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          4,\n          6,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24945015,\n        \"min\": 0,\n        \"max\": 100000000,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          3,\n          5,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"character\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"\\u4e09\",\n          \"\\u4e94\",\n          \"\\u4e5d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_MQlmJDi7Y9N",
        "outputId": "f34bd7aa-0890-454d-8656-8fa2e1ec0fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1262ef27-a379-4057-b2f6-319dccfc0692\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1262ef27-a379-4057-b2f6-319dccfc0692\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.zip to data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n"
      ],
      "metadata": {
        "id": "n_KBO-6LEToC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ver carpeta creada después de descomprimir\n",
        "print(os.listdir(\"data/data/\")[:10])\n",
        "\n",
        "print(\"Cantidad de imágenes:\", len(os.listdir(\"data/data\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaJDmGIKErMz",
        "outputId": "d21c2bf7-f1fa-45e3-a526-13cc2c5db0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_45_8_8.jpg', 'input_7_3_2.jpg', 'input_100_2_8.jpg', 'input_63_10_5.jpg', 'input_75_6_15.jpg', 'input_29_2_15.jpg', 'input_24_7_7.jpg', 'input_58_1_8.jpg', 'input_83_3_10.jpg', 'input_79_1_14.jpg']\n",
            "Cantidad de imágenes: 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "data_path = 'data/data/'\n",
        "img_path = os.path.join(data_path, os.listdir(data_path)[14000])\n",
        "img = Image.open(img_path)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Dq9aC68eE3h1",
        "outputId": "6da254cb-2033-4d82-e72a-33798b2b18fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.character.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LT9i7g9CT_p",
        "outputId": "0eba451f-9a65-4f8f-fbcb-bdc171e27174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['九', '十', '百', '千', '万', '亿', '零', '一', '二', '三', '四', '五', '六',\n",
              "       '七', '八'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vincular cada imagen con su fila del CSV: Agregar la columna con el nombre del archivo"
      ],
      "metadata": {
        "id": "gzmz8sacDSCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df[\"filename\"] = \"input_\" + df[\"suite_id\"].astype(str) + \"_\" \\\n",
        "                           + df[\"sample_id\"].astype(str) + \"_\" \\\n",
        "                           + df[\"code\"].astype(str) + \".jpg\""
      ],
      "metadata": {
        "id": "LSMbgjI7CmRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear 'X' (paths de imágenes) y 'y' (caracteres):"
      ],
      "metadata": {
        "id": "9W60fIPBw3RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_path = 'data/data'\n",
        "X = [os.path.join(image_path, fname) for fname in df[\"filename\"]]\n",
        "y = df[\"character\"].values"
      ],
      "metadata": {
        "id": "HeDx9BI9wtzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos:"
      ],
      "metadata": {
        "id": "hs2saZ8UxfG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ejemplo X[0]:\", X[0])  # ruta de la primera imagen\n",
        "print(\"Ejemplo y[0]:\", y[0])  # etiqueta (ej: 九)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcqMmotyxeT4",
        "outputId": "a633f548-5e27-473c-f335-e2c4e7c95b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo X[0]: data/data/input_1_1_10.jpg\n",
            "Ejemplo y[0]: 九\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = Image.open(X[3134])\n",
        "plt.imshow(img)\n",
        "print(\"X: \", X[3134])\n",
        "print(\"Y: \", y[3134])\n",
        "plt.title(f\"Etiqueta: {y[3134]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "fLmMA-ofA5je",
        "outputId": "bcce74eb-b0b2-4c47-e2ee-5762ca8a334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  data/data/input_20_4_13.jpg\n",
            "Y:  千\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X → son los paths de las imágenes (luego se convierten en tensores/matrices).\n",
        "\n",
        "y → es el character, que es la variable objetivo a predecir."
      ],
      "metadata": {
        "id": "8baqaRZwxeig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapear las etiquetas (character) a números, ya que PyTorch no trabaja con strings como etiquetas y necesitamos índices enteros."
      ],
      "metadata": {
        "id": "VHINDbCY1xC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "y_idx, classes = pd.factorize(y)  # y_idx = números, classes = mapeo inverso\n",
        "print(\"Número de clases:\", len(classes))\n",
        "print(\"Primeras clases:\", classes[:10])\n",
        "print(\"Numeros mapeados: \", y_idx)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdI6UCRTystY",
        "outputId": "4b50f2cc-67b6-4664-c1a2-6a4a5445e7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de clases: 15\n",
            "Primeras clases: ['九' '十' '百' '千' '万' '亿' '零' '一' '二' '三']\n",
            "Numeros mapeados:  [ 0  0  0 ... 14 14 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset y Transformaciones con PyTorch**\n",
        "\n",
        "En lugar de cargar todas las imágenes a memoria, lo mejor es definir un Dataset personalizado que cargue cada imagen cuando se necesita."
      ],
      "metadata": {
        "id": "aCSV06A6159j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Definir transformaciones: resize y tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")  # abrir imagen\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "9jR2a0In183c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es muy importante, consiste en separar los datos en 3 subconjuntos:\n",
        "- **Entrenamiendo (train) (80%)**: Se usa para que el modelo aprenda los patrones de los datos.\n",
        "- **Validacion (10%)**: Sirve para ajustar parámetros y evaluar el desempeño del modelo durante el entrenamiento, sin usar los datos de prueba.\n",
        "- **Prueba (10%)**: Se reserva hasta el final para medir el rendimiento real del modelo en datos nunca vistos."
      ],
      "metadata": {
        "id": "o0WnMllpmSH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# dividir en train (80%), val (10%), test (10%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_idx, test_size=0.2, random_state=random.randint(0, 100)\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=random.randint(0, 100)\n",
        ")"
      ],
      "metadata": {
        "id": "xL5IXJE_kSd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crear datasets y dataloaders**\n",
        "\n",
        "* **`ImageDataset`** es una clase que hereda de `torch.utils.data.Dataset`.\n",
        "\n",
        "* Su función es **gestionar tus datos de manera ordenada**:\n",
        "\n",
        "  * Sabe **cuántas imágenes hay** (`__len__`).\n",
        "  * Sabe **cómo cargar una imagen y su etiqueta** (`__getitem__`).\n",
        "  * Aplica transformaciones automáticamente (como resize, y  ToTensor).\n",
        "\n",
        "* `X_train`, `X_val`, `X_test` → **rutas** a las imágenes.\n",
        "\n",
        "* `y_train`, `y_val`, `y_test` → **etiquetas** correspondientes.\n",
        "\n",
        "* `transform=transform` → aplica los pasos de **preprocesamiento** que definiste.\n",
        "\n",
        "Resultado: cada `train_dataset`/`val_dataset`/`test_dataset` ahora es un **contenedor de datos listo para PyTorch**.\n",
        "\n",
        "#### DataLoader\n",
        "\n",
        "Hace varias cosas importantes:\n",
        "\n",
        "1. **Crea batches**:\n",
        "\n",
        "   * **`batch_size=64`** → devuelve 64 imágenes + 64 etiquetas por iteración.\n",
        "   * Esto es más eficiente que pasar toda la dataset completa de una vez.\n",
        "\n",
        "2. **Maneja el orden y el shuffle**:\n",
        "\n",
        "   * **`shuffle=True`** en entrenamiento → mezcla los datos en cada época para que el modelo no aprenda un orden fijo.\n",
        "   * `shuffle=False` en validación/test → el orden no importa, queremos reproducibilidad.\n",
        "\n",
        "#### Resumen\n",
        "\n",
        "* **Dataset** → “qué datos tenemos y cómo acceder a ellos”.\n",
        "* **DataLoader** → “cómo entregar los datos al modelo en batches, en orden aleatorio si queremos”.\n",
        "\n"
      ],
      "metadata": {
        "id": "EuuI4bbk3KbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = ImageDataset(X_train, y_train, transform=transform)\n",
        "val_dataset   = ImageDataset(X_val, y_val, transform=transform)\n",
        "test_dataset  = ImageDataset(X_test, y_test, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "uz2zKrE43Jjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definir un modelo**\n",
        "\n",
        "En PyTorch hablamos de **capas que tienen parámetros aprendibles** (weights/biases), aunque también consideramos **capas funcionales como ReLU o pooling.**\n",
        "\n",
        "**Capas con parámetros:**\n",
        "\n",
        "conv1 = nn.Conv2d(3, 32, 3, padding=1) → convolucional\n",
        "\n",
        "conv2 = nn.Conv2d(32, 64, 3, padding=1) → convolucional\n",
        "\n",
        "fc1 = nn.Linear(64*16*16, 128) → fully connected\n",
        "\n",
        "fc2 = nn.Linear(128, num_classes) → fully connected\n",
        "\n",
        "Total = 4 capas con parámetros\n",
        "\n",
        "**Capas “funcionales” (sin parámetros):**\n",
        "\n",
        "\n",
        "F.relu(...) → ReLU (activación)\n",
        "\n",
        "self.pool(...) → MaxPooling (reducción de tamaño)\n",
        "\n",
        "Si contás todas las transformaciones en forward, incluyendo activaciones y pooling:\n",
        "\n",
        "Conv1 → 2. ReLU → 3. Pool → 4. Conv2 → 5. ReLU → 6. Pool → 7. FC1 → 8. ReLU → 9. FC2\n",
        "\n",
        "Total de pasos en forward: 9, pero solo 4 tienen parámetros entrenables."
      ],
      "metadata": {
        "id": "jXVWpJXr3UG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64*16*16, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64*16*16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "0xcGYG9N3USY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Definir dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hgnjbA3N6Rk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir modelo\n",
        "model = SimpleCNN(num_classes=len(classes)).to(device)"
      ],
      "metadata": {
        "id": "oSrFKz9w6UdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criterio y optimizador\n",
        "perdida = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "mZ2K9iHX6WC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento"
      ],
      "metadata": {
        "id": "2sZshCIt3aEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de épocas\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Entrenamiento ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = perdida(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # --- Validación ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            outputs = model(X_batch)\n",
        "            loss = perdida(outputs, y_batch)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calcular accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    # Métricas por época\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f} \"\n",
        "          f\"Val Acc: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wSENS_Q3aQ7",
        "outputId": "8a83980e-6083-49b3-b229-f0956fb0216e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15] Train Loss: 0.1226 Val Loss: 0.2097 Val Acc: 94.53%\n",
            "Epoch [2/15] Train Loss: 0.1361 Val Loss: 0.2189 Val Acc: 94.27%\n",
            "Epoch [3/15] Train Loss: 0.1437 Val Loss: 0.2392 Val Acc: 93.93%\n",
            "Epoch [4/15] Train Loss: 0.1445 Val Loss: 0.2588 Val Acc: 93.27%\n",
            "Epoch [5/15] Train Loss: 0.1523 Val Loss: 0.2175 Val Acc: 94.73%\n",
            "Epoch [6/15] Train Loss: 0.1491 Val Loss: 0.2142 Val Acc: 94.13%\n",
            "Epoch [7/15] Train Loss: 0.1491 Val Loss: 0.2369 Val Acc: 94.67%\n",
            "Epoch [8/15] Train Loss: 0.1497 Val Loss: 0.2381 Val Acc: 93.47%\n",
            "Epoch [9/15] Train Loss: 0.1505 Val Loss: 0.2597 Val Acc: 93.53%\n",
            "Epoch [10/15] Train Loss: 0.1549 Val Loss: 0.2066 Val Acc: 94.87%\n",
            "Epoch [11/15] Train Loss: 0.1511 Val Loss: 0.2139 Val Acc: 95.13%\n",
            "Epoch [12/15] Train Loss: 0.1517 Val Loss: 0.2613 Val Acc: 93.67%\n",
            "Epoch [13/15] Train Loss: 0.1536 Val Loss: 0.2450 Val Acc: 93.60%\n",
            "Epoch [14/15] Train Loss: 0.1501 Val Loss: 0.2372 Val Acc: 93.20%\n",
            "Epoch [15/15] Train Loss: 0.1517 Val Loss: 0.2204 Val Acc: 95.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El paso final consiste en evaluar el modelo entreanado sobre el conjunto de datos de test"
      ],
      "metadata": {
        "id": "h-q17OIH9Qeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Evaluación en el set de test\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model.eval()  # modo evaluación\n",
        "with torch.no_grad():\n",
        "    for X_batch, true_y in test_loader:\n",
        "        X_batch, true_y = X_batch.to(device), true_y.to(device)\n",
        "\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_true.extend(true_y.cpu().numpy())\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
        "\n",
        "# Reporte de clasificación\n",
        "# target_names los armamos como strings de los números\n",
        "num_clases = len(set(y_true))  # detecta cuántas clases tenés\n",
        "target_names = [str(i) for i in range(num_clases)]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "KGE0SpbYwKa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc3723e-067e-4364-fe81-fc80abd22028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.9407\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89        96\n",
            "           1       0.95      0.93      0.94        99\n",
            "           2       0.91      0.95      0.93        94\n",
            "           3       0.94      0.95      0.94        98\n",
            "           4       0.90      0.94      0.92        98\n",
            "           5       0.90      0.94      0.92        97\n",
            "           6       0.97      0.97      0.97       115\n",
            "           7       0.95      1.00      0.97        93\n",
            "           8       0.93      0.91      0.92       107\n",
            "           9       0.92      0.93      0.92        95\n",
            "          10       1.00      0.94      0.97        99\n",
            "          11       0.97      0.93      0.95       103\n",
            "          12       0.97      0.93      0.95        97\n",
            "          13       0.95      0.93      0.94       100\n",
            "          14       0.98      0.97      0.98       109\n",
            "\n",
            "    accuracy                           0.94      1500\n",
            "   macro avg       0.94      0.94      0.94      1500\n",
            "weighted avg       0.94      0.94      0.94      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy general\n",
        "\n",
        "```\n",
        "Accuracy on the test set: 0.9647\n",
        "```\n",
        "\n",
        "* La **exactitud** global es 96.47%.\n",
        "* Esto significa que **el modelo predijo correctamente aproximadamente 964 de cada 1000 imágenes**.\n",
        "\n",
        "\n",
        "### Tabla de métricas por clase\n",
        "\n",
        "Cada fila corresponde a una clase (en tu caso los números `0,1,2,...,14`). Las columnas son:\n",
        "\n",
        "* **precision** (precisión)\n",
        "\n",
        "  Qué porcentaje de las predicciones que el modelo dijo que eran esa clase **fueron correctas**.\n",
        "\n",
        "* **recall** (recuperación o sensibilidad)\n",
        "\n",
        "  Qué porcentaje de **los verdaderos ejemplos de esa clase fueron detectados correctamente**.\n",
        "\n",
        "* **f1-score**\n",
        "\n",
        "  Es la media armónica de precisión y recall → balancea ambos.\n",
        "\n",
        "* **support**\n",
        "  Cantidad de ejemplos reales de esa clase en el test set.\n",
        "\n",
        "\n",
        "### Promedios\n",
        "\n",
        "* **accuracy** → 0.96 (ya lo vimos, precisión global).\n",
        "* **macro avg** → promedio simple de precision, recall y f1-score entre todas las clases.\n",
        "* **weighted avg** → promedio ponderado por la cantidad de ejemplos de cada clase (support), útil si algunas clases tienen más muestras que otras.\n"
      ],
      "metadata": {
        "id": "ZSOEOUlm9rMu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}